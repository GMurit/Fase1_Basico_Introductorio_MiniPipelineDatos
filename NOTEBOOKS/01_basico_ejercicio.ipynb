{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "591f9c31-88b4-4538-b301-36f36f33875a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista: [10, 20, 30, 40, 50]\n",
      "Media: 30.0\n",
      "Diccionario: {'Alice': 25, 'Bob': 30, 'Charlie': 22}\n",
      "Edad promedio: 25.666666666666668\n",
      "Conjunto único de frutas: {'orange', 'banana', 'apple'}\n",
      "Diccionario con tupla como clave: {(10, 20): 'Parque'}\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# PASO 1: Básicos para empezar con datos. Listas, Diccionarios, Sets y Tuplas.\n",
    "# ==================================================\n",
    "\n",
    "\n",
    "# LISTAS\n",
    "numbers = [10, 20, 30, 40, 50]\n",
    "print(\"Lista:\", numbers)\n",
    "print(\"Media:\", sum(numbers)/len(numbers))\n",
    "\n",
    "# DICCIONARIOS\n",
    "ages = {\"Alice\": 25, \"Bob\": 30, \"Charlie\": 22}\n",
    "print(\"Diccionario:\", ages)\n",
    "print(\"Edad promedio:\", sum(ages.values())/len(ages))\n",
    "\n",
    "# SETS\n",
    "fruits = [\"apple\", \"banana\", \"apple\", \"orange\"]\n",
    "unique_fruits = set(fruits)\n",
    "print(\"Conjunto único de frutas:\", unique_fruits)\n",
    "\n",
    "# TUPLAS como clave en diccionario\n",
    "coords = (10, 20)\n",
    "locations = {coords: \"Parque\"}\n",
    "print(\"Diccionario con tupla como clave:\", locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94a1d9a4-43c0-4fbe-beb5-14e174907fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lista: [2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 6, 2, 3, 9, 6]\n",
      "Media: 4.117647058823529\n",
      "Asignaturas: {'Lengua': 6, 'Inglés': 9, 'Programación': 8}\n",
      "Media de Notas: 7.666666666666667\n",
      "colores unicos: {'amarillo', 'rojo', 'azul'}\n",
      "Diccionario con tupla como clave: {('fresa', 'vainilla'): 'batidos'}\n"
     ]
    }
   ],
   "source": [
    "#PRÁCTICA\n",
    "\n",
    "#LISTA\n",
    "numeros = [2,2,3,3,3,4,4,4,4,5,5,5,6,2,3,9,6]\n",
    "print(\"Lista:\",numeros)\n",
    "print(\"Media:\",sum(numeros)/len(numeros))\n",
    "\n",
    "#DICCIONARIOS\n",
    "asignaturas = {\"Lengua\": 6, \"Inglés\": 9, \"Programación\": 8}\n",
    "print(\"Asignaturas:\",asignaturas)\n",
    "print(\"Media de Notas:\", sum(asignaturas.values())/len(asignaturas))\n",
    "\n",
    "#SETS\n",
    "colores = [\"rojo\",\"rojo\",\"amarillo\",\"azul\",\"azul\"]\n",
    "colores_unicos = set(colores)\n",
    "print(\"colores unicos:\", colores_unicos)\n",
    "\n",
    "#TUPLAS\n",
    "sabor = (\"fresa\",\"vainilla\")\n",
    "bebida = {sabor:\"batidos\"}\n",
    "print(\"Diccionario con tupla como clave:\", bebida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8e16e2a-d3e7-40bd-945d-b2889e80a9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   id         10 non-null     int64  \n",
      " 1   categoria  10 non-null     object \n",
      " 2   valor      9 non-null      float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 372.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "# ==================================================\n",
    "# PASO 2: DataFrame con pandas y numpy\n",
    "# ==================================================\n",
    "\n",
    "# Importamos pandas y numpy para trabjar en este ejercicio\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Vamos a trabajar con los siguientes datos que es un diccionario de listas.\n",
    "data = {\n",
    "    \"id\": range(1, 11),\n",
    "    \"categoria\": [\"A\",\"B\",\"A\",\"A\",\"B\",\"C\",\"B\",\"A\",\"C\",\"B\"],\n",
    "    \"valor\": [10, 20, 30, None, 50, 60, 70, 80, 90, 100]\n",
    "}\n",
    "\n",
    "#Convertimos nuestro diccionario de listas en un conjunto de datos, donde cada clave será una columna.\n",
    "df = pd.DataFrame(data)\n",
    "df_raw = pd.DataFrame(data)\n",
    "\n",
    "# ==================================================\n",
    "# Paso 2.2: Explorar datos\n",
    "# ==================================================\n",
    "\n",
    "#Ahora, con df.Head(), vemos los primeros 5 registros de nuestra tabla.\n",
    "df.head()\n",
    "#Para obtener información general del dataframe\n",
    "df.info()\n",
    "\n",
    "#Para obtener estadísticas descriptivas de la columna \"valor\"\n",
    "df[\"valor\"].describe()\n",
    "\n",
    "# ==================================================\n",
    "# Paso 2.3: Limpiar datos (rellenar valores nulos)\n",
    "# ==================================================\n",
    "\n",
    "#Para revisar los valores nulos por columna\n",
    "df.isna().sum()\n",
    "\n",
    "#Rellenamos el valor nulo de la columna valor con la mediana\n",
    "df[\"valor\"] = df[\"valor\"].fillna(df[\"valor\"].median())\n",
    "\n",
    "#Revisamos de nuevo los valores nulos\n",
    "df.isna().sum()\n",
    "\n",
    "#Mostramos el dataframe para ver\n",
    "df.head(10)\n",
    "\n",
    "# ==================================================\n",
    "# Paso 2.4: Crear columna derivada 'valor_log'\n",
    "# ==================================================\n",
    "\n",
    "#Creamos una columna derivada para hacer logarirmo de valor. Esto sirve cuando tenemos dataframes con datos muy sesgados, por ejemplo que vayan de 0 a 1millon, y la diferencia entre ellos en graficos no se vea tan aplastatant y resulta mas fácil el analisis.\n",
    "df[\"valor_log\"] = np.log1p(df[\"valor\"])\n",
    "\n",
    "#Mostramos el dataframe actualizado\n",
    "df\n",
    "\n",
    "# ==================================================\n",
    "# Paso 2.5: Agrupar por categoría y calcular métricas\n",
    "# ==================================================\n",
    "\n",
    "#Vamos a agrupar por categoria y luego calcular la media de los valores de cada categoria y contar cuantos registros tienen cada categoría. Y lo metemos en un nuevo dataframa llamado \"agrupados\".\n",
    "agrupados = df.groupby(\"categoria\").agg({\"valor\":[\"mean\",\"count\"]})\n",
    "\n",
    "#Mostramos el datafram\n",
    "agrupados\n",
    "\n",
    "# ==================================================\n",
    "# Paso 2.6: Filtrar filas según condición\n",
    "# ==================================================\n",
    "\n",
    "#Vamos a filtrar por una condición y esa filtración la guardamos en un nuevo dataframe.\n",
    "df_filtrado = df[df[\"valor\"]> 50]\n",
    "\n",
    "#Mostramos el dataframe de filtrado\n",
    "df_filtrado\n",
    "\n",
    "# ==================================================\n",
    "# Paso 2.7: Guardar DataFrame en CSV y Parquet\n",
    "# ==================================================\n",
    "\n",
    "#Ahora, guardamos el dataframe sucio tanto en un archivo CSV como PARQET con el index en false para que no nos muestre la columna por defecto de indices.\n",
    "df_raw.to_csv(\"../DATA/RAW_DATA/01_basico_datos_sucios.csv\", index = False)\n",
    "df_raw.to_parquet(\"../DATA/RAW_DATA/01_basico_datos_sucios.parquet\", engine = \"pyarrow\", index = False) #especificamos el engine si tenemos más de libreria para gestionar archivos parquet. En este caso, tenemos pyarrow y fastparquet instalados en el entorno.\n",
    "#Ahora igual pero con los datos limpios.\n",
    "df.to_csv(\"../DATA/CLEAN_DATA/01_basico_datos_limpios.csv\", index = False)\n",
    "df.to_parquet(\"../DATA/CLEAN_DATA/01_basico_datos_limpios.parquet\", engine = \"pyarrow\", index = False)\n",
    "#También vamos a guardar el dataframe que creamos como consecuencia del filtrado pero antes vamos a reindexar la nueva tabla que se habrán debido desordenar.\n",
    "df_filtrado.reset_index(drop = True, inplace = True) #Con esta línea conseguimos reindexar los índices de la tabla filtrada.\n",
    "#Ahora la guardamos\n",
    "df.to_csv(\"../DATA/CLEAN_DATA/01_basico_datos_limpios_filtrado_mayor_50.csv\", index = False)\n",
    "df.to_parquet(\"../DATA/CLEAN_DATA/01_basico_datos_limpios_filtrado_mayor_50.parquet\", engine = \"pyarrow\", index = False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d61c19-ed1d-4dbe-950f-d9cb21bce411",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a55d56-f068-44a5-91c3-e5b1a5ff927b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834caeea-edb9-47cf-975d-c04310257d84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594f8fe8-89b0-416f-9ae1-d776e2b3bad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e750cfac-a4fe-4836-acab-fa6a927e5ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c601341-c238-43a6-a2b9-591bccc02f13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dataeng)",
   "language": "python",
   "name": "dataeng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
